# -*- coding: utf-8 -*-
"""CSET340Lab5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19jTt8YgEOYfSi9mbhiRRvi0twt1cY8zF

### TASK **1**
"""

# Task 1.1: JPEG Compression (Lossy)
from google.colab import files
from PIL import Image
import os
from IPython.display import display

# Prompt to upload an image file
print("Please upload an image file:")
uploaded = files.upload()

# Retrieve the first uploaded image
image_filename = list(uploaded.keys())[0]
original_image = Image.open(image_filename)

print("\nOriginal Image:")
display(original_image)

jpeg_filename = "compressed_image.jpeg"
original_image.convert("RGB").save(jpeg_filename, "JPEG", quality=20)
print("\nJPEG Compressed Image:")
jpeg_image = Image.open(jpeg_filename)
display(jpeg_image)

# Display file sizes
original_size = os.path.getsize(image_filename)
jpeg_size = os.path.getsize(jpeg_filename)
print("\nFile Size Comparison:")
print("Original image size: {:.2f} KB".format(original_size / 1024))
print("JPEG compressed image size: {:.2f} KB".format(jpeg_size / 1024))

# Task 1.2: PNG Compression (Lossless with Optimization)
from google.colab import files
from PIL import Image
import os
from IPython.display import display

# Prompt to upload an image file (if running separately, you can reuse the image from previous cell)
print("Please upload an image file:")
uploaded = files.upload()

# Retrieve the first uploaded image
image_filename = list(uploaded.keys())[0]
original_image = Image.open(image_filename)

print("\nOriginal Image:")
display(original_image)

# Save the image in PNG format with optimization enabled
png_filename = "compressed_image.png"
original_image.save(png_filename, "PNG", optimize=True)

print("\nPNG Compressed Image:")
png_image = Image.open(png_filename)
display(png_image)

# Display file sizes
original_size = os.path.getsize(image_filename)
png_size = os.path.getsize(png_filename)
print("\nFile Size Comparison:")
print("Original image size: {:.2f} KB".format(original_size / 1024))
print("PNG compressed image size: {:.2f} KB".format(png_size / 1024))

"""### TASK **2**"""

# Task 2 - MNIST
# Block 1: Load Data, 80-20 Split, Build & Train CNN

import numpy as np
import matplotlib.pyplot as plt
from keras.datasets import mnist
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# 1. Load MNIST dataset (60k train, 10k test)
(X_train_full, y_train_full), (X_test_full, y_test_full) = mnist.load_data()

# 2. Combine into one dataset of 70,000 images
X_all = np.concatenate((X_train_full, X_test_full), axis=0)
y_all = np.concatenate((y_train_full, y_test_full), axis=0)

# 3. Perform an 80-20 split manually
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,
                                                    test_size=0.20,
                                                    random_state=42)

# 4. Preprocess the data
# MNIST images are 28x28, but CNNs typically expect (height, width, channels).
# So we reshape to (28, 28, 1) and normalize pixel values.
X_train = X_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0
X_test  = X_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0

# Convert labels to one-hot encoded vectors
y_train_cat = to_categorical(y_train, num_classes=10)
y_test_cat  = to_categorical(y_test, num_classes=10)

# 5. Build a simple CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# 6. Train the model (50 epochs)
history = model.fit(X_train, y_train_cat,
                    epochs=50,
                    batch_size=64,
                    validation_split=0.1,  # 10% of training set for validation
                    verbose=1)